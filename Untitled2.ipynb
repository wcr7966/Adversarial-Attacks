{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>christma tree farm pictur</td>\n",
       "      <td>ham</td>\n",
       "      <td>spampy/datasets/enron\\enron1\\ham\\0001.1999-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vastar resourc inc gari product high island la...</td>\n",
       "      <td>ham</td>\n",
       "      <td>spampy/datasets/enron\\enron1\\ham\\0002.1999-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>calpin daili ga nomin calpin daili ga nomin doc</td>\n",
       "      <td>ham</td>\n",
       "      <td>spampy/datasets/enron\\enron1\\ham\\0003.1999-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>issu fyi see note alreadi done stella forward ...</td>\n",
       "      <td>ham</td>\n",
       "      <td>spampy/datasets/enron\\enron1\\ham\\0004.1999-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meter nov alloc fyi forward lauri allen hou ec...</td>\n",
       "      <td>ham</td>\n",
       "      <td>spampy/datasets/enron\\enron1\\ham\\0005.1999-12-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33711</th>\n",
       "      <td>iso q good news c edaliss val edumm vl eoggra ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spampy/datasets/enron\\enron6\\spam\\5995.2005-07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33712</th>\n",
       "      <td>prescript medicin special precis put buck back...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spampy/datasets/enron\\enron6\\spam\\5997.2005-07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33713</th>\n",
       "      <td>next gener onlin pharmaci readi rock let man r...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spampy/datasets/enron\\enron6\\spam\\5998.2005-07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33714</th>\n",
       "      <td>bloow time time learn last time longer bed rea...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spampy/datasets/enron\\enron6\\spam\\5999.2005-07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33715</th>\n",
       "      <td>dear sir interest hi need softwar give link ht...</td>\n",
       "      <td>spam</td>\n",
       "      <td>spampy/datasets/enron\\enron6\\spam\\6000.2005-07...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33716 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message label  \\\n",
       "0                             christma tree farm pictur    ham   \n",
       "1      vastar resourc inc gari product high island la...   ham   \n",
       "2       calpin daili ga nomin calpin daili ga nomin doc    ham   \n",
       "3      issu fyi see note alreadi done stella forward ...   ham   \n",
       "4      meter nov alloc fyi forward lauri allen hou ec...   ham   \n",
       "...                                                  ...   ...   \n",
       "33711  iso q good news c edaliss val edumm vl eoggra ...  spam   \n",
       "33712  prescript medicin special precis put buck back...  spam   \n",
       "33713  next gener onlin pharmaci readi rock let man r...  spam   \n",
       "33714  bloow time time learn last time longer bed rea...  spam   \n",
       "33715  dear sir interest hi need softwar give link ht...  spam   \n",
       "\n",
       "                                                    path  \n",
       "0      spampy/datasets/enron\\enron1\\ham\\0001.1999-12-...  \n",
       "1      spampy/datasets/enron\\enron1\\ham\\0002.1999-12-...  \n",
       "2      spampy/datasets/enron\\enron1\\ham\\0003.1999-12-...  \n",
       "3      spampy/datasets/enron\\enron1\\ham\\0004.1999-12-...  \n",
       "4      spampy/datasets/enron\\enron1\\ham\\0005.1999-12-...  \n",
       "...                                                  ...  \n",
       "33711  spampy/datasets/enron\\enron6\\spam\\5995.2005-07...  \n",
       "33712  spampy/datasets/enron\\enron6\\spam\\5997.2005-07...  \n",
       "33713  spampy/datasets/enron\\enron6\\spam\\5998.2005-07...  \n",
       "33714  spampy/datasets/enron\\enron6\\spam\\5999.2005-07...  \n",
       "33715  spampy/datasets/enron\\enron6\\spam\\6000.2005-07...  \n",
       "\n",
       "[33716 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "import os\n",
    "import numpy as np\n",
    "import codecs\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "csv.field_size_limit(500 * 1024 * 1024)\n",
    "with open(\"messages.csv\", \"r\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    messages = []\n",
    "    for row in reader:\n",
    "        messages.append(row[1:])\n",
    "messages = messages[1:]\n",
    "messages = pd.DataFrame(messages, columns=['message', 'label', 'path'])\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test and store the path in x_train_path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "messages['label'] = messages['label'].replace('ham', 0)\n",
    "messages['label'] = messages['label'].replace('spam', 1)\n",
    "\n",
    "messages_label = messages['label']\n",
    "message_path = messages['path']\n",
    "x = messages['message']\n",
    "y = messages_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12481</th>\n",
       "      <td>fw special issuealert big texa news wood ferc ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30513</th>\n",
       "      <td>pre qualifi appli home loan mortgag novemb upd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33368</th>\n",
       "      <td>new softwar breacher annul spot young want pow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24089</th>\n",
       "      <td>hotel show last chanc exhibit hotel show may a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29485</th>\n",
       "      <td>percent med levitra cial save xanax valium phe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12644</th>\n",
       "      <td>global market monitor prepar presentaton argen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7655</th>\n",
       "      <td>confirm order automat confirm order place use ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17685</th>\n",
       "      <td>start date hourahead hour start date hourahead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6726</th>\n",
       "      <td>softwar licens karla august vacat month franc ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25513</th>\n",
       "      <td>readi get hello viagra med struggl men erectil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6743 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message\n",
       "12481  fw special issuealert big texa news wood ferc ...\n",
       "30513  pre qualifi appli home loan mortgag novemb upd...\n",
       "33368  new softwar breacher annul spot young want pow...\n",
       "24089  hotel show last chanc exhibit hotel show may a...\n",
       "29485  percent med levitra cial save xanax valium phe...\n",
       "...                                                  ...\n",
       "12644  global market monitor prepar presentaton argen...\n",
       "7655   confirm order automat confirm order place use ...\n",
       "17685  start date hourahead hour start date hourahead...\n",
       "6726   softwar licens karla august vacat month franc ...\n",
       "25513  readi get hello viagra med struggl men erectil...\n",
       "\n",
       "[6743 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p41, p5, p41_y, p5_y = train_test_split(x, y, test_size=0.2)\n",
    "p31, p4, p31_y, p4_y = train_test_split(p41, p41_y, test_size=0.25)\n",
    "p21, p3, p21_y, p3_y = train_test_split(p31, p31_y, test_size=1/3)\n",
    "p1, p2, p1_y, p2_y = train_test_split(p21, p21_y, test_size=0.5)\n",
    "\n",
    "pd_p1 = pd.DataFrame(p1)\n",
    "pd_p1.to_csv(\"pd_p1.csv\")\n",
    "pd_p2 = pd.DataFrame(p2)\n",
    "pd_p2.to_csv(\"pd_p2.csv\")\n",
    "pd_p3 = pd.DataFrame(p3)\n",
    "pd_p3.to_csv(\"pd_p3.csv\")\n",
    "pd_p4 = pd.DataFrame(p4)\n",
    "pd_p4.to_csv(\"pd_p4.csv\")\n",
    "pd_p5 = pd.DataFrame(p5)\n",
    "pd_p5.to_csv(\"pd_p5.csv\")\n",
    "\n",
    "pd_p1_y = pd.DataFrame(p1_y)\n",
    "pd_p1_y.to_csv(\"pd_p1_y.csv\")\n",
    "pd_p2_y = pd.DataFrame(p2_y)\n",
    "pd_p2_y.to_csv(\"pd_p2_y.csv\")\n",
    "pd_p3_y = pd.DataFrame(p3_y)\n",
    "pd_p3_y.to_csv(\"pd_p3_y.csv\")\n",
    "pd_p4_y = pd.DataFrame(p4_y)\n",
    "pd_p4_y.to_csv(\"pd_p4_y.csv\")\n",
    "pd_p5_y = pd.DataFrame(p5_y)\n",
    "pd_p5_y.to_csv(\"pd_p5_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myopen(mydir):\n",
    "    pd1 = []\n",
    "    index1 = []\n",
    "    with open(mydir, \"r\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for j, row in reader:\n",
    "            index1.append(j)\n",
    "            if row == '0' or row == '1':\n",
    "                pd1.append(int(row))\n",
    "            else: \n",
    "                pd1.append(row)\n",
    "    pd1 = pd1[1:]\n",
    "    index1 = index1[1:]\n",
    "    pd1 = pd.Series(pd1, index = index1)\n",
    "    return pd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_p1 = myopen(\"pd_p1.csv\")\n",
    "pd_p2 = myopen(\"pd_p2.csv\")\n",
    "pd_p3 = myopen(\"pd_p3.csv\")\n",
    "pd_p4 = myopen(\"pd_p4.csv\")\n",
    "pd_p5 = myopen(\"pd_p5.csv\")\n",
    "\n",
    "pd_p1_y = myopen(\"pd_p1_y.csv\")\n",
    "pd_p2_y = myopen(\"pd_p2_y.csv\")\n",
    "pd_p3_y = myopen(\"pd_p3_y.csv\")\n",
    "pd_p4_y = myopen(\"pd_p4_y.csv\")\n",
    "pd_p5_y = myopen(\"pd_p5_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd_p1.append(pd_p2).append(pd_p3).append(pd_p5)\n",
    "x_test = pd_p4\n",
    "\n",
    "y_train = pd_p1_y.append(pd_p2_y).append(pd_p3_y).append(pd_p5_y)\n",
    "y_test = pd_p4_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6743\n",
      "6743\n"
     ]
    }
   ],
   "source": [
    "print(len(pd_p1))\n",
    "print(len(pd_p1_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_path = []\n",
    "for i, v in x_train.items():\n",
    "    i = int(i)\n",
    "    x_train_path.append((i, message_path[i]))\n",
    "    \n",
    "x_test_path = []\n",
    "for i, v in x_test.items():\n",
    "    i = int(i)\n",
    "    x_test_path.append((i, message_path[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaci</th>\n",
       "      <th>aaaahhhhhh</th>\n",
       "      <th>aaadrizzl</th>\n",
       "      <th>aaaenerfax</th>\n",
       "      <th>aaal</th>\n",
       "      <th>aaaplusdirect</th>\n",
       "      <th>aab</th>\n",
       "      <th>...</th>\n",
       "      <th>zztc</th>\n",
       "      <th>zzucpkow</th>\n",
       "      <th>zzvffofbj</th>\n",
       "      <th>zzw</th>\n",
       "      <th>zzx</th>\n",
       "      <th>zzxtfeerekvwkug</th>\n",
       "      <th>zzxxst</th>\n",
       "      <th>zzyudgpd</th>\n",
       "      <th>zzzglvaa</th>\n",
       "      <th>zzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26968</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26969</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26970</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26971</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26972</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26973 rows × 106292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        aa  aaa  aaaa  aaaaci  aaaahhhhhh  aaadrizzl  aaaenerfax  aaal  \\\n",
       "0      0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "1      0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "2      0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "3      0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "4      0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "...    ...  ...   ...     ...         ...        ...         ...   ...   \n",
       "26968  0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "26969  0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "26970  0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "26971  0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "26972  0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "\n",
       "       aaaplusdirect  aab  ...  zztc  zzucpkow  zzvffofbj  zzw  zzx  \\\n",
       "0                0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "1                0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "2                0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "3                0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "4                0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "...              ...  ...  ...   ...       ...        ...  ...  ...   \n",
       "26968            0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "26969            0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "26970            0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "26971            0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "26972            0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "\n",
       "       zzxtfeerekvwkug  zzxxst  zzyudgpd  zzzglvaa  zzzz  \n",
       "0                  0.0     0.0       0.0       0.0   0.0  \n",
       "1                  0.0     0.0       0.0       0.0   0.0  \n",
       "2                  0.0     0.0       0.0       0.0   0.0  \n",
       "3                  0.0     0.0       0.0       0.0   0.0  \n",
       "4                  0.0     0.0       0.0       0.0   0.0  \n",
       "...                ...     ...       ...       ...   ...  \n",
       "26968              0.0     0.0       0.0       0.0   0.0  \n",
       "26969              0.0     0.0       0.0       0.0   0.0  \n",
       "26970              0.0     0.0       0.0       0.0   0.0  \n",
       "26971              0.0     0.0       0.0       0.0   0.0  \n",
       "26972              0.0     0.0       0.0       0.0   0.0  \n",
       "\n",
       "[26973 rows x 106292 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Tf-idf for train datasets\n",
    "vect = TfidfVectorizer()\n",
    "tfidf_train = vect.fit_transform(x_train)\n",
    "tfidf_matrix_train = pd.DataFrame(tfidf_train.toarray(), columns = vect.get_feature_names())\n",
    "headers = vect.get_feature_names()\n",
    "tfidf_matrix_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aaaaci</th>\n",
       "      <th>aaaahhhhhh</th>\n",
       "      <th>aaadrizzl</th>\n",
       "      <th>aaaenerfax</th>\n",
       "      <th>aaal</th>\n",
       "      <th>aaaplusdirect</th>\n",
       "      <th>aab</th>\n",
       "      <th>...</th>\n",
       "      <th>zztc</th>\n",
       "      <th>zzucpkow</th>\n",
       "      <th>zzvffofbj</th>\n",
       "      <th>zzw</th>\n",
       "      <th>zzx</th>\n",
       "      <th>zzxtfeerekvwkug</th>\n",
       "      <th>zzxxst</th>\n",
       "      <th>zzyudgpd</th>\n",
       "      <th>zzzglvaa</th>\n",
       "      <th>zzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6738</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6739</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6740</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6741</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6742</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6743 rows × 106292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aa  aaa  aaaa  aaaaci  aaaahhhhhh  aaadrizzl  aaaenerfax  aaal  \\\n",
       "0     0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "1     0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "2     0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "3     0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "4     0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "...   ...  ...   ...     ...         ...        ...         ...   ...   \n",
       "6738  0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "6739  0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "6740  0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "6741  0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "6742  0.0  0.0   0.0     0.0         0.0        0.0         0.0   0.0   \n",
       "\n",
       "      aaaplusdirect  aab  ...  zztc  zzucpkow  zzvffofbj  zzw  zzx  \\\n",
       "0               0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "1               0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "2               0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "3               0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "4               0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "...             ...  ...  ...   ...       ...        ...  ...  ...   \n",
       "6738            0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "6739            0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "6740            0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "6741            0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "6742            0.0  0.0  ...   0.0       0.0        0.0  0.0  0.0   \n",
       "\n",
       "      zzxtfeerekvwkug  zzxxst  zzyudgpd  zzzglvaa  zzzz  \n",
       "0                 0.0     0.0       0.0       0.0   0.0  \n",
       "1                 0.0     0.0       0.0       0.0   0.0  \n",
       "2                 0.0     0.0       0.0       0.0   0.0  \n",
       "3                 0.0     0.0       0.0       0.0   0.0  \n",
       "4                 0.0     0.0       0.0       0.0   0.0  \n",
       "...               ...     ...       ...       ...   ...  \n",
       "6738              0.0     0.0       0.0       0.0   0.0  \n",
       "6739              0.0     0.0       0.0       0.0   0.0  \n",
       "6740              0.0     0.0       0.0       0.0   0.0  \n",
       "6741              0.0     0.0       0.0       0.0   0.0  \n",
       "6742              0.0     0.0       0.0       0.0   0.0  \n",
       "\n",
       "[6743 rows x 106292 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tf-idf for test datsets\n",
    "tfidf_test = vect.transform(x_test)\n",
    "tfidf_matrix_test = pd.DataFrame(tfidf_test.toarray(), columns = vect.get_feature_names())\n",
    "tfidf_matrix_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build SVM\n",
      "Find the best params\n",
      "Finish Train\n",
      "The best training parameters are:  [('C', 1)]\n",
      "Train SVM\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CClassifierSVM{'classes': CArray(2,)(dense: [0 1]), 'n_features': 106292, 'preprocess': None, 'n_jobs': 1, 'C': 1.0, 'class_weight': None, 'w': CArray(1, 106292)(sparse: (0, 81980) 0.037349991956252916  (0, 71399) 0.03200460184631901  (0, 58187) 0.028518800517331536  (0, 57281) 0.040657785107124256  (0, 15442) 0.05964410441498885  (0, 104573) 0.09654555076978681  (0, 91525) 0.10168648272798353  (0, 91038) 0.10168648272798353  (0, 76414) 0.10576706998756438  (0, 73891) 0.10576706998756438  (0, 73644) 0.10576706998756438  (0, 53378) 0.098791259991966  (0, 36549) 0.10168648272798353  (0, 28904) 0.10576706998756438  (0, 26751) 0.10576706998756438  (0, 23325) 0.08956974077418844  (0, 19858) 0.098791259991966  (0, 6511) 0.10168648272798353  (0, 101084) 0.015465951843963186  (0, 100717) 0.01694317757848104  (0, 84945) 0.01694317757848104  (0, 82708) 0.0158256994492007  (0, 73118) 0.01694317757848104  (0, 71294) 0.0158256994492007  (0, 56074) 0.014194816534193315  : :  (0, 44035) 0.5335880870016468  (0, 41677) -1.3086073281074242  (0, 32514) -0.25639360618952034  (0, 29964) -0.6379227889463064  (0, 28708) 0.3079939677723134  (0, 28621) -6.898316462133731  (0, 27698) 0.026743800138037357  (0, 27655) 0.2871696204512634  (0, 27067) -0.29774747286066044  (0, 26791) 0.10620312746912305  (0, 21463) -0.7642537971143348  (0, 20558) -0.270751666639715  (0, 19691) -0.03943269119962432  (0, 18600) 0.03175703106883731  (0, 18572) 0.3996162694206965  (0, 17598) -0.36227848315681294  (0, 17564) -0.0634535254806816  (0, 17536) -1.0762465722241876  (0, 17436) -0.1311241471017345  (0, 17384) -0.2845927107266319  (0, 14961) 0.037061105175766496  (0, 11598) 0.31319026737050887  (0, 9683) -0.4872287494536722  (0, 3886) -1.1935153603906978  (0, 933) -0.09220312607660322), 'b': CArray(1,)(dense: [0.535617]), 'alpha': None, 'sv_idx': None, 'kernel': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from secml.data import CDataset\n",
    "from secml.data.splitter import CDataSplitterKFold\n",
    "from secml.ml.classifiers import CClassifierSVM\n",
    "from secml.ml.peval.metrics import CMetricAccuracy\n",
    "from secml.ml.peval.metrics import CMetricConfusionMatrix\n",
    "\n",
    "from secml.ml.classifiers.multiclass import CClassifierMulticlassOVA\n",
    "from secml.ml.kernels import CKernelLinear\n",
    "\n",
    "nb_col = tfidf_train.size\n",
    "\n",
    "tr_set = CDataset(tfidf_train, y_train)\n",
    "\n",
    "\n",
    "# Train the SVM\n",
    "print(\"Build SVM\")\n",
    "xval_splitter = CDataSplitterKFold()\n",
    "clf_lin = CClassifierSVM()\n",
    "\n",
    "\n",
    "xval_lin_params = {'C': [1]}\n",
    "\n",
    "print(\"Find the best params\")\n",
    "\n",
    "best_lin_params = clf_lin.estimate_parameters(\n",
    "    dataset = tr_set,\n",
    "    parameters = xval_lin_params,\n",
    "    splitter = xval_splitter,\n",
    "    metric = 'accuracy',\n",
    "    perf_evaluator = 'xval'\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Finish Train\")\n",
    "print(\"The best training parameters are: \", [(k, best_lin_params[k]) for k in sorted(best_lin_params)])\n",
    "\n",
    "print(\"Train SVM\")\n",
    "clf_lin.fit(tr_set.X, tr_set.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDataset{'X': CArray(6743, 106292)(sparse: (0, 104066) 0.031058293442085286  (0, 99978) 0.021860893617808942  (0, 99641) 0.10496491730026943  (0, 98190) 0.026408120771934808  (0, 97158) 0.3758084642805929  (0, 96380) 0.017924778036153905  (0, 95162) 0.05107547725985605  (0, 92967) 0.15367858624157035  (0, 91827) 0.01585268240328143  (0, 91371) 0.02260056165713833  (0, 90939) 0.0610722656896288  (0, 90218) 0.1134505677463461  (0, 89611) 0.024874610205727857  (0, 88599) 0.04886411905149069  (0, 87880) 0.03681648804020712  (0, 87743) 0.04744382505205558  (0, 86982) 0.020770465147357815  (0, 86808) 0.029610193177122428  (0, 85729) 0.025205974012599924  (0, 84289) 0.03246148317722166  (0, 84056) 0.0306275494014894  (0, 84037) 0.027402449050965793  (0, 83392) 0.032016383997380236  (0, 82956) 0.026134302448106203  (0, 82285) 0.018478877295018018  : :  (6741, 70094) 0.07033142705539464  (6741, 68105) 0.09496968431890036  (6741, 61895) 0.08133195074028948  (6741, 60807) 0.07109811860757499  (6741, 57075) 0.12814204630509315  (6741, 56052) 0.060092422476109714  (6741, 51848) 0.06512071773996594  (6741, 48974) 0.07609505031976212  (6741, 44736) 0.0516175882121968  (6741, 39125) 0.10825431182308856  (6741, 37463) 0.5468216760036233  (6741, 31513) 0.07190584646297347  (6741, 28621) 0.04984889315395382  (6741, 24132) 0.14369710545522452  (6741, 21754) 0.12939781056206778  (6741, 19716) 0.07627187180322413  (6741, 18848) 0.14998905956469213  (6741, 17384) 0.04492117818940922  (6741, 17263) 0.11632109804361457  (6741, 13010) 0.08032614501733973  (6741, 12747) 0.09052170185991881  (6741, 10656) 0.08304132926454422  (6741, 8727) 0.1361769475553078  (6741, 5664) 0.07625918923973635  (6741, 5530) 0.07241094987237755), 'Y': CArray(6743,)(dense: [0 0 1 ... 0 0 1]), 'header': None}\n",
      "Accuracy on test set: 98.99%\n",
      "Confusion Matrix: \n",
      "CArray([[3261   54]\n",
      " [  14 3414]])\n",
      "False Positive Rate: 1.12%\n",
      "False Negative Rate: 0.47%\n"
     ]
    }
   ],
   "source": [
    "# Test the Classifier\n",
    "ts_set = CDataset(tfidf_test, y_test)\n",
    "print(ts_set)\n",
    "\n",
    "y_pred = clf_lin.predict(ts_set.X)\n",
    "metric = CMetricAccuracy()\n",
    "acc = metric.performance_score(y_true=ts_set.Y, y_pred=y_pred)\n",
    "\n",
    "confusion_matrix = CMetricConfusionMatrix() \n",
    "cm = confusion_matrix.performance_score(y_true=ts_set.Y, y_pred=y_pred)\n",
    "\n",
    "print(\"Accuracy on test set: {:.2%}\".format(acc))\n",
    "print(\"Confusion Matrix: \")\n",
    "print(cm)\n",
    "print(\"False Positive Rate: {:.2%}\".format(39/(39+3445)))\n",
    "\n",
    "print(\"False Negative Rate: {:.2%}\".format(15/(15+3203)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24118,\n",
       "  'spampy/datasets/enron\\\\enron5\\\\spam\\\\0108.2002-05-08.SA_and_HP.spam.txt'),\n",
       " (26691,\n",
       "  'spampy/datasets/enron\\\\enron5\\\\spam\\\\3728.2005-07-06.SA_and_HP.spam.txt'),\n",
       " (10511,\n",
       "  'spampy/datasets/enron\\\\enron2\\\\spam\\\\3837.2005-07-04.SA_and_HP.spam.txt'),\n",
       " (32915, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\4919.2005-05-20.BG.spam.txt'),\n",
       " (10039,\n",
       "  'spampy/datasets/enron\\\\enron2\\\\spam\\\\2018.2005-06-22.SA_and_HP.spam.txt'),\n",
       " (18925, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\1172.2004-05-14.GP.spam.txt'),\n",
       " (21253, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\4278.2005-02-14.GP.spam.txt'),\n",
       " (30938, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\2309.2004-12-24.BG.spam.txt'),\n",
       " (21766, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\4968.2005-04-22.GP.spam.txt'),\n",
       " (20082, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\2725.2004-10-14.GP.spam.txt'),\n",
       " (18157, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\0156.2004-01-10.GP.spam.txt'),\n",
       " (18290, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\0328.2004-02-03.GP.spam.txt'),\n",
       " (24706,\n",
       "  'spampy/datasets/enron\\\\enron5\\\\spam\\\\0942.2002-08-05.SA_and_HP.spam.txt'),\n",
       " (30673, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\1957.2004-12-04.BG.spam.txt'),\n",
       " (4481, 'spampy/datasets/enron\\\\enron1\\\\spam\\\\2840.2004-11-16.GP.spam.txt'),\n",
       " (21974, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\5244.2005-05-21.GP.spam.txt'),\n",
       " (15362, 'spampy/datasets/enron\\\\enron3\\\\spam\\\\1187.2004-11-04.BG.spam.txt'),\n",
       " (21879, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\5116.2005-05-06.GP.spam.txt'),\n",
       " (29241, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\0034.2004-08-03.BG.spam.txt'),\n",
       " (21377, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\4445.2005-02-23.GP.spam.txt'),\n",
       " (26775,\n",
       "  'spampy/datasets/enron\\\\enron5\\\\spam\\\\3845.2005-07-12.SA_and_HP.spam.txt'),\n",
       " (24918,\n",
       "  'spampy/datasets/enron\\\\enron5\\\\spam\\\\1232.2002-09-17.SA_and_HP.spam.txt'),\n",
       " (27360,\n",
       "  'spampy/datasets/enron\\\\enron5\\\\spam\\\\4683.2005-07-19.SA_and_HP.spam.txt'),\n",
       " (19213, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\1558.2004-06-26.GP.spam.txt'),\n",
       " (27060,\n",
       "  'spampy/datasets/enron\\\\enron5\\\\spam\\\\4253.2005-07-17.SA_and_HP.spam.txt'),\n",
       " (33652, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\5914.2005-07-23.BG.spam.txt'),\n",
       " (21352, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\4411.2005-02-22.GP.spam.txt'),\n",
       " (31839, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\3496.2005-02-17.BG.spam.txt'),\n",
       " (30688, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\1977.2004-12-05.BG.spam.txt'),\n",
       " (10079,\n",
       "  'spampy/datasets/enron\\\\enron2\\\\spam\\\\2168.2005-06-23.SA_and_HP.spam.txt'),\n",
       " (19781, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\2317.2004-09-11.GP.spam.txt'),\n",
       " (30618, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\1883.2004-11-29.BG.spam.txt'),\n",
       " (24304,\n",
       "  'spampy/datasets/enron\\\\enron5\\\\spam\\\\0370.2002-06-02.SA_and_HP.spam.txt'),\n",
       " (31015, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\2409.2004-12-29.BG.spam.txt'),\n",
       " (9752,\n",
       "  'spampy/datasets/enron\\\\enron2\\\\spam\\\\0925.2002-07-25.SA_and_HP.spam.txt'),\n",
       " (25881,\n",
       "  'spampy/datasets/enron\\\\enron5\\\\spam\\\\2578.2005-06-28.SA_and_HP.spam.txt'),\n",
       " (19800, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\2344.2004-09-13.GP.spam.txt'),\n",
       " (22275, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\5644.2005-07-15.GP.spam.txt'),\n",
       " (4609, 'spampy/datasets/enron\\\\enron1\\\\spam\\\\3319.2004-12-27.GP.spam.txt'),\n",
       " (18086, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\0064.2003-12-26.GP.spam.txt'),\n",
       " (20674, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\3511.2004-12-11.GP.spam.txt'),\n",
       " (10398,\n",
       "  'spampy/datasets/enron\\\\enron2\\\\spam\\\\3346.2005-06-30.SA_and_HP.spam.txt'),\n",
       " (10576,\n",
       "  'spampy/datasets/enron\\\\enron2\\\\spam\\\\4143.2005-07-06.SA_and_HP.spam.txt'),\n",
       " (10005,\n",
       "  'spampy/datasets/enron\\\\enron2\\\\spam\\\\1881.2005-06-22.SA_and_HP.spam.txt'),\n",
       " (30993, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\2378.2004-12-28.BG.spam.txt'),\n",
       " (3757, 'spampy/datasets/enron\\\\enron1\\\\spam\\\\0328.2004-01-29.GP.spam.txt'),\n",
       " (20333, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\3061.2004-11-10.GP.spam.txt'),\n",
       " (26883,\n",
       "  'spampy/datasets/enron\\\\enron5\\\\spam\\\\4001.2005-07-15.SA_and_HP.spam.txt'),\n",
       " (24919,\n",
       "  'spampy/datasets/enron\\\\enron5\\\\spam\\\\1233.2002-09-18.SA_and_HP.spam.txt'),\n",
       " (20034, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\2661.2004-10-10.GP.spam.txt'),\n",
       " (22460, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\5889.2005-08-24.GP.spam.txt'),\n",
       " (18450, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\0540.2004-03-04.GP.spam.txt'),\n",
       " (32608, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\4516.2005-04-23.BG.spam.txt'),\n",
       " (31002, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\2390.2004-12-28.BG.spam.txt'),\n",
       " (21688, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\4861.2005-04-10.GP.spam.txt'),\n",
       " (5014, 'spampy/datasets/enron\\\\enron1\\\\spam\\\\4675.2005-06-10.GP.spam.txt'),\n",
       " (4496, 'spampy/datasets/enron\\\\enron1\\\\spam\\\\2923.2004-11-23.GP.spam.txt'),\n",
       " (10499,\n",
       "  'spampy/datasets/enron\\\\enron2\\\\spam\\\\3773.2005-07-03.SA_and_HP.spam.txt'),\n",
       " (22372, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\5774.2005-08-03.GP.spam.txt'),\n",
       " (30129, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\1227.2004-10-25.BG.spam.txt'),\n",
       " (10456,\n",
       "  'spampy/datasets/enron\\\\enron2\\\\spam\\\\3593.2005-07-02.SA_and_HP.spam.txt'),\n",
       " (31733, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\3355.2005-02-10.BG.spam.txt'),\n",
       " (5014, 'spampy/datasets/enron\\\\enron1\\\\spam\\\\4675.2005-06-10.GP.spam.txt'),\n",
       " (27424,\n",
       "  'spampy/datasets/enron\\\\enron5\\\\spam\\\\4773.2005-07-19.SA_and_HP.spam.txt'),\n",
       " (31248, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\2720.2005-01-14.BG.spam.txt'),\n",
       " (15399, 'spampy/datasets/enron\\\\enron3\\\\spam\\\\1324.2004-11-10.BG.spam.txt'),\n",
       " (10639,\n",
       "  'spampy/datasets/enron\\\\enron2\\\\spam\\\\4397.2005-07-12.SA_and_HP.spam.txt'),\n",
       " (15693, 'spampy/datasets/enron\\\\enron3\\\\spam\\\\2388.2005-01-12.BG.spam.txt'),\n",
       " (15562, 'spampy/datasets/enron\\\\enron3\\\\spam\\\\1911.2004-12-16.BG.spam.txt'),\n",
       " (10834,\n",
       "  'spampy/datasets/enron\\\\enron2\\\\spam\\\\5109.2005-07-19.SA_and_HP.spam.txt'),\n",
       " (32943, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\4958.2005-05-23.BG.spam.txt'),\n",
       " (10780,\n",
       "  'spampy/datasets/enron\\\\enron2\\\\spam\\\\4912.2005-07-17.SA_and_HP.spam.txt'),\n",
       " (22474, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\5909.2005-08-26.GP.spam.txt'),\n",
       " (30920, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\2285.2004-12-23.BG.spam.txt'),\n",
       " (33484, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\5688.2005-07-10.BG.spam.txt'),\n",
       " (21352, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\4411.2005-02-22.GP.spam.txt'),\n",
       " (15464, 'spampy/datasets/enron\\\\enron3\\\\spam\\\\1543.2004-11-24.BG.spam.txt'),\n",
       " (25268,\n",
       "  'spampy/datasets/enron\\\\enron5\\\\spam\\\\1712.2005-06-22.SA_and_HP.spam.txt'),\n",
       " (9995,\n",
       "  'spampy/datasets/enron\\\\enron2\\\\spam\\\\1841.2005-06-21.SA_and_HP.spam.txt'),\n",
       " (33268, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\5398.2005-06-23.BG.spam.txt'),\n",
       " (30024, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\1085.2004-10-17.BG.spam.txt'),\n",
       " (19537, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\1989.2004-08-11.GP.spam.txt'),\n",
       " (24163,\n",
       "  'spampy/datasets/enron\\\\enron5\\\\spam\\\\0172.2002-05-15.SA_and_HP.spam.txt'),\n",
       " (32653, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\4574.2005-04-28.BG.spam.txt'),\n",
       " (4756, 'spampy/datasets/enron\\\\enron1\\\\spam\\\\3845.2005-02-15.GP.spam.txt'),\n",
       " (20845, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\3736.2004-12-30.GP.spam.txt'),\n",
       " (32819, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\4794.2005-05-12.BG.spam.txt'),\n",
       " (32182, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\3941.2005-03-16.BG.spam.txt'),\n",
       " (4775, 'spampy/datasets/enron\\\\enron1\\\\spam\\\\3894.2005-02-22.GP.spam.txt'),\n",
       " (19056, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\1347.2004-06-02.GP.spam.txt'),\n",
       " (24905,\n",
       "  'spampy/datasets/enron\\\\enron5\\\\spam\\\\1215.2002-09-16.SA_and_HP.spam.txt'),\n",
       " (26997,\n",
       "  'spampy/datasets/enron\\\\enron5\\\\spam\\\\4160.2005-07-16.SA_and_HP.spam.txt'),\n",
       " (4949, 'spampy/datasets/enron\\\\enron1\\\\spam\\\\4455.2005-05-07.GP.spam.txt'),\n",
       " (30288, 'spampy/datasets/enron\\\\enron6\\\\spam\\\\1436.2004-11-06.BG.spam.txt'),\n",
       " (4791, 'spampy/datasets/enron\\\\enron1\\\\spam\\\\3947.2005-03-01.GP.spam.txt'),\n",
       " (27175,\n",
       "  'spampy/datasets/enron\\\\enron5\\\\spam\\\\4423.2005-07-18.SA_and_HP.spam.txt'),\n",
       " (4807, 'spampy/datasets/enron\\\\enron1\\\\spam\\\\3985.2005-03-06.GP.spam.txt'),\n",
       " (19488, 'spampy/datasets/enron\\\\enron4\\\\spam\\\\1923.2004-08-02.GP.spam.txt'),\n",
       " (26372,\n",
       "  'spampy/datasets/enron\\\\enron5\\\\spam\\\\3267.2005-07-03.SA_and_HP.spam.txt'),\n",
       " (27353,\n",
       "  'spampy/datasets/enron\\\\enron5\\\\spam\\\\4671.2005-07-19.SA_and_HP.spam.txt')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from secml.array import CArray\n",
    "from secml.adv.attacks.evasion import CAttackEvasionPGD\n",
    "\n",
    "nb_attack=100\n",
    "\n",
    "class_to_attack=1\n",
    "cnt = 0\n",
    "\n",
    "ori_examples2_x = []\n",
    "ori_examples2_y = []\n",
    "number_list = []\n",
    "for i in range(nb_attack):\n",
    "    #take a point at random being the starting point of the attack\n",
    "    idx_candidates = np.where(y_test == class_to_attack)\n",
    "    #select nb_init_pts points randomly in candidates and make them move\n",
    "    rn = np.random.choice(idx_candidates[0].size, 1)\n",
    "    x0,y0 =ts_set[idx_candidates[0][rn[0]],:].X, ts_set[idx_candidates[0][rn[0]],:].Y\n",
    "    number_list.append(x_test_path[idx_candidates[0][rn[0]]])\n",
    "    \n",
    "    x0=x0.astype(float)\n",
    "    y0=y0.astype(int)\n",
    "    x2 = x0.tondarray()[0]\n",
    "    y2 = y0.tondarray()[0]\n",
    "    \n",
    "    ori_examples2_x.append(x2)\n",
    "    ori_examples2_y.append(y2)\n",
    "    \n",
    "number_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Number: 0\n",
      "Current Number: 1\n",
      "Current Number: 2\n",
      "Current Number: 3\n",
      "Current Number: 4\n",
      "Current Number: 5\n",
      "Current Number: 6\n",
      "Current Number: 7\n",
      "Current Number: 8\n",
      "Current Number: 9\n",
      "Current Number: 10\n",
      "Current Number: 11\n",
      "Current Number: 12\n",
      "Current Number: 13\n",
      "Current Number: 14\n",
      "Current Number: 15\n",
      "Current Number: 16\n",
      "Current Number: 17\n",
      "Current Number: 18\n",
      "Current Number: 19\n",
      "Current Number: 20\n",
      "Current Number: 21\n",
      "Current Number: 22\n",
      "Current Number: 23\n",
      "Current Number: 24\n",
      "Current Number: 25\n",
      "Current Number: 26\n",
      "Current Number: 27\n",
      "Current Number: 28\n",
      "Current Number: 29\n",
      "Current Number: 30\n",
      "Current Number: 31\n",
      "Current Number: 32\n",
      "Current Number: 33\n",
      "Current Number: 34\n",
      "Current Number: 35\n",
      "Current Number: 36\n",
      "Current Number: 37\n",
      "Current Number: 38\n",
      "Current Number: 39\n",
      "Current Number: 40\n",
      "Current Number: 41\n",
      "Current Number: 42\n",
      "Current Number: 43\n",
      "Current Number: 44\n",
      "Current Number: 45\n",
      "Current Number: 46\n",
      "Current Number: 47\n",
      "Current Number: 48\n",
      "Current Number: 49\n",
      "Current Number: 50\n",
      "Current Number: 51\n",
      "Current Number: 52\n",
      "Current Number: 53\n",
      "Current Number: 54\n",
      "Current Number: 55\n",
      "Current Number: 56\n",
      "Current Number: 57\n",
      "Current Number: 58\n",
      "Current Number: 59\n",
      "Current Number: 60\n",
      "Current Number: 61\n",
      "Current Number: 62\n",
      "Current Number: 63\n",
      "Current Number: 64\n",
      "Current Number: 65\n",
      "Current Number: 66\n",
      "Current Number: 67\n",
      "Current Number: 68\n",
      "Current Number: 69\n",
      "Current Number: 70\n",
      "Current Number: 71\n",
      "Current Number: 72\n",
      "Current Number: 73\n",
      "Current Number: 74\n",
      "Current Number: 75\n",
      "Current Number: 76\n",
      "Current Number: 77\n",
      "Current Number: 78\n",
      "Current Number: 79\n",
      "Current Number: 80\n",
      "Current Number: 81\n",
      "Current Number: 82\n",
      "Current Number: 83\n",
      "Current Number: 84\n",
      "Current Number: 85\n",
      "Current Number: 86\n",
      "Current Number: 87\n",
      "Current Number: 88\n",
      "Current Number: 89\n",
      "Current Number: 90\n",
      "Current Number: 91\n",
      "Current Number: 92\n",
      "Current Number: 93\n",
      "Current Number: 94\n",
      "Current Number: 95\n",
      "Current Number: 96\n",
      "Current Number: 97\n",
      "Current Number: 98\n",
      "Current Number: 99\n",
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Perform adversarial attacks\n",
    "noise_type = 'l2'  # Type of perturbation 'l1' or 'l2'\n",
    "dmax = 0.09 # Maximum perturbation\n",
    "lb, ub = 0, 1  # Bounds of the attack space. Can be set to `None` for unbounded\n",
    "\n",
    "solver_params = {\n",
    "    'eta': 0.01,\n",
    "    'max_iter': 20,\n",
    "    'eps': 1e-6}\n",
    "\n",
    "#set lower bound and upper bound respectively to 0 and 1 since all features are Boolean\n",
    "pgd_attack = CAttackEvasionPGD(\n",
    "    classifier=clf_lin,\n",
    "    double_init_ds=tr_set,\n",
    "    distance=noise_type,\n",
    "    dmax=dmax,\n",
    "    lb=lb, ub=ub,\n",
    "    solver_params=solver_params)\n",
    "\n",
    "\n",
    "ad_examples_x = []\n",
    "ad_examples_y = []\n",
    "cnt = 0\n",
    "for i in range(len(ori_examples2_x)):\n",
    "    print(\"Current Number:\", i)\n",
    "    x0 = ori_examples2_x[i]\n",
    "    y0 = ori_examples2_y[i]\n",
    "\n",
    "    y_pred_pgd, _, adv_ds_pgd, _ = pgd_attack.run(x0, y0)\n",
    "\n",
    "    if y_pred_pgd.item() == 0:\n",
    "        cnt = cnt + 1\n",
    "\n",
    "    ad_examples_x.append(adv_ds_pgd.X.tondarray()[0])\n",
    "    ad_examples_y.append(y_pred_pgd.item())\n",
    "\n",
    "    attack_pt = adv_ds_pgd.X.tondarray()[0]\n",
    "print(\"Accuracy:\", cnt/nb_attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>6.032145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaa</th>\n",
       "      <td>7.870424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaa</th>\n",
       "      <td>10.104016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaaci</th>\n",
       "      <td>10.509482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaahhhhhh</th>\n",
       "      <td>10.509482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzxtfeerekvwkug</th>\n",
       "      <td>10.509482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzxxst</th>\n",
       "      <td>10.509482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzyudgpd</th>\n",
       "      <td>10.509482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzzglvaa</th>\n",
       "      <td>10.509482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzzz</th>\n",
       "      <td>8.258190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106292 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0\n",
       "aa                6.032145\n",
       "aaa               7.870424\n",
       "aaaa             10.104016\n",
       "aaaaci           10.509482\n",
       "aaaahhhhhh       10.509482\n",
       "...                    ...\n",
       "zzxtfeerekvwkug  10.509482\n",
       "zzxxst           10.509482\n",
       "zzyudgpd         10.509482\n",
       "zzzglvaa         10.509482\n",
       "zzzz              8.258190\n",
       "\n",
       "[106292 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori_examples2_x = np.array(ori_examples2_x)\n",
    "ori_examples2_y = np.array(ori_examples2_y)\n",
    "ad_examples_x = np.array(ad_examples_x)\n",
    "ad_examples_y = np.array(ad_examples_y)\n",
    "\n",
    "ori_dataframe = pd.DataFrame(ori_examples2_x, columns = vect.get_feature_names())\n",
    "ad_dataframe = pd.DataFrame(ad_examples_x, columns = vect.get_feature_names())\n",
    "\n",
    "ad_dataframe['ad_label'] = ad_examples_y\n",
    "ad_success = ad_dataframe.loc[ad_dataframe.ad_label == 0]\n",
    "ori_success = ori_dataframe.loc[ad_dataframe.ad_label == 0]\n",
    "ad_fail = ad_dataframe.loc[ad_dataframe.ad_label == 1]\n",
    "ori_fail = ori_dataframe.loc[ad_dataframe.ad_label == 1]\n",
    "\n",
    "ad_success_x = ad_success.drop(columns = ['ad_label'])\n",
    "ad_fail_x = ad_fail.drop(columns = ['ad_label'])\n",
    "result = (ad_success_x - ori_success)\n",
    "\n",
    "vect.idf_\n",
    "IDF = pd.DataFrame(vect.idf_.T, index=vect.get_feature_names())\n",
    "IDF.to_csv(\"idf.csv\")\n",
    "IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>enron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vinc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>louis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>attach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>kal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>octob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>cdnow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>beenladen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>aol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0       enron\n",
       "1        vinc\n",
       "2       louis\n",
       "3       thank\n",
       "4      attach\n",
       "..        ...\n",
       "95        kal\n",
       "96      octob\n",
       "97      cdnow\n",
       "98  beenladen\n",
       "99        aol\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 2\n",
    "x2result1 = result\n",
    "x2result1 = np.array(x2result1)\n",
    "x2result = result\n",
    "x2result = x2result.multiply(x2result1)\n",
    "\n",
    " \n",
    "sum_number = x2result.sum()/cnt\n",
    "\n",
    "\n",
    "sum_number = pd.DataFrame(sum_number, columns = ['sum_number'])\n",
    "sum_number = sum_number.sort_values(by='sum_number', ascending=False, inplace=False)\n",
    "sum_number\n",
    "#sum_number = sum_number.loc[var_number['var_number']>0]\n",
    "#print(sum_number.index[:200])\n",
    "#print(sum_number.index[:500])\n",
    "\n",
    "sum_number_pd = pd.DataFrame(sum_number.index[:100])\n",
    "sum_number_pd.to_csv(\"x2result.csv\")\n",
    "sum_number_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ori > 0, ad = 0\n",
    "# The dispearing features\n",
    "ad1 = ad_success_x\n",
    "ori1 = ori_success\n",
    "\n",
    "ori2 = ori1.loc[:, (ori1>=0).all(axis=0)]\n",
    "ori = ori2.loc[:, ~(ori2==0).all(axis=0)]\n",
    "\n",
    "ad = ad1.loc[:,ori.columns]\n",
    "ad = ad.loc[:, (ad>=0).all(axis=0)]\n",
    "ad = ad.loc[:, ~(ad>0).all(axis=0)]\n",
    "\n",
    "ori1_ad0_columns = ad.columns\n",
    "ori1_ad0_columns = pd.DataFrame(ori1_ad0_columns)\n",
    "ori1_ad0_columns.to_csv(\"ori1_ad0_columns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ori = 0, ad > 0\n",
    "# The adding features\n",
    "ad11 = ad_success_x\n",
    "ori11 = ori_success\n",
    "\n",
    "ori21 = ori11.loc[:, (ori11>=0).all(axis=0)]\n",
    "ori22 = ori21.loc[:, ~(ori21>0).all(axis=0)]\n",
    "\n",
    "ad22 = ad11.loc[:,ori22.columns]\n",
    "ad22 = ad22.loc[:, (ad22>=0).all(axis=0)]\n",
    "ad22 = ad22.loc[:, ~(ad22==0).all(axis=0)]\n",
    "\n",
    "ori0_ad1_columns = ad22.columns\n",
    "ori0_ad1_columns = pd.DataFrame(ori0_ad1_columns)\n",
    "ori0_ad1_columns.to_csv(\"ori0_ad1_columns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 271\n",
      "2 391\n",
      "3 503\n",
      "4 1264\n",
      "5 1569\n",
      "6 1958\n",
      "Count:  1958\n"
     ]
    }
   ],
   "source": [
    "from nltk import stem\n",
    "stemmer = stem.PorterStemmer()\n",
    "cut_model = nltk.WordPunctTokenizer()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "# words14 = \"enrononlin fundi cera dailyupd jobsearch congrad ena listbot counterparti calger sitara jhherbert kaminski solarc clickathom\"\n",
    "# words14 = \"eyeforenergi ena counterparti kaminski enrononlin clickathom jhherbert cera topica calger sitara cdnow beenladen\"\n",
    "words14 = \" cdnow kaminski enrononlin ena\"\n",
    "spam_cnt = 0\n",
    "d2 = \"spampy/datasets/enron/\"\n",
    "for r in range(1, 7):\n",
    "    d3 = d2 + \"enron\" + str(r)+\"/spam\"\n",
    "    emails2 = [os.path.join(d3, f) for f in os.listdir(d3)]\n",
    "    for j in emails2:\n",
    "        with codecs.open(j, \"rb\", encoding='utf_8_sig', errors='ignore') as m:\n",
    "            #print(j)\n",
    "            choose_email = []\n",
    "            line_str = \"\"\n",
    "            for line in m:\n",
    "                for word in line:\n",
    "                    if word.startswith(\"http\"):\n",
    "                        word = \"URL\"\n",
    "                    word = stemmer.stem(word)\n",
    "\n",
    "                line = re.sub(r'[^a-zA-Z\\s]', '', string=line)\n",
    "                line = line.lower()\n",
    "                line = line.strip()\n",
    "                tokens = cut_model.tokenize(line)\n",
    "                line = [stemmer.stem(token) for token in tokens if token not in stopwords]\n",
    "\n",
    "                line = ' '.join(line)\n",
    "                line_str = line_str+line+\" \"\n",
    "            line_str = line_str+words14\n",
    "            choose_email.append(line_str)\n",
    "        message_14_email = pd.DataFrame(choose_email, columns = [\"message\"])\n",
    "        message_14_tf_idf = vect.transform(message_14_email[\"message\"])\n",
    "        message_14_tf_idf = pd.DataFrame(message_14_tf_idf.toarray(), columns = vect.get_feature_names())\n",
    "        #print(message_14_tf_idf)\n",
    "        message_14_y = [1]\n",
    "        message_14_y = pd.Series(message_14_y)\n",
    "        message_CData = CDataset(message_14_tf_idf, message_14_y)\n",
    "        message_14_pred = clf_lin.predict(message_CData.X)\n",
    "        # print(message_14_pred)\n",
    "        if message_14_pred == 0:\n",
    "            spam_cnt = spam_cnt+1\n",
    "        #break\n",
    "    print(r, spam_cnt)\n",
    "print(\"Count: \", spam_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect = \"cdnow kaminski enrononlin ena\"\n",
    "union = \"kal topica cdnow ferc lokay cera jhherbert enrononlin sitara listbot calger wassup pjm kaminski counterparti eyeforenergi clickathom reactionsnet ena beenladen\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
